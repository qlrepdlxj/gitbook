
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>네이버 영화 리뷰 분석 - 테스트 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="9.md" />
    
    
    <link rel="prev" href="7.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    빅데이터 영화 분석
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="1.html">
            
                <a href="1.html">
            
                    
                    1. 데이터 분석 설계
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.2" data-path="2.html">
            
                <a href="2.html">
            
                    
                    2. 데이터 준비
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.3" data-path="3.html">
            
                <a href="3.html">
            
                    
                    3. 데이터 가공
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.4" data-path="3.1.html">
            
                <a href="3.1.html">
            
                    
                    3-1 영화진흥위원회 OPENAPI 사용
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.5" data-path="3.2.html">
            
                <a href="3.2.html">
            
                    
                    3-2 영화진흥위원회 OPENAPI 사용2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.6" data-path="3.3.html">
            
                <a href="3.3.html">
            
                    
                    3-3
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.7" data-path="3.4.html">
            
                <a href="3.4.html">
            
                    
                    3-4
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.8" data-path="3.5.html">
            
                <a href="3.5.html">
            
                    
                    3-5
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.9" data-path="3.6.html">
            
                <a href="3.6.html">
            
                    
                    3-6
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.10" data-path="4.html">
            
                <a href="4.html">
            
                    
                    4. 데이터 활용
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.11" data-path="5.html">
            
                <a href="5.html">
            
                    
                    5. 데이터 분석
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.12" data-path="6.html">
            
                <a href="6.html">
            
                    
                    6. 결론 도출
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="7.html">
            
                <a href="7.html">
            
                    
                    링크
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3" data-path="8.html">
            
                <a href="8.html">
            
                    
                    네이버 영화 리뷰 분석 - 테스트
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="9.md">
            
                <span>
            
                    
                    시각화 예제 1
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="10.md">
            
                <span>
            
                    
                    시각화 예제 2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="AWS.html">
            
                <a href="AWS.html">
            
                    
                    AWS
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >네이버 영화 리뷰 분석 - 테스트</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <pre><code class="lang-python"><span class="hljs-comment"># https://cyc1am3n.github.io/2018/11/10/classifying_korean_movie_review.html</span>
<span class="hljs-comment">#-*- coding: utf-8 -*-</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">read_data</span><span class="hljs-params">(filename)</span>:</span>
    <span class="hljs-keyword">with</span> open(filename, <span class="hljs-string">&apos;r&apos;</span>, encoding=<span class="hljs-string">&apos;utf-8&apos;</span>) <span class="hljs-keyword">as</span> f:
        data = [line.split(<span class="hljs-string">&apos;\t&apos;</span>) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.read().splitlines()]
        <span class="hljs-comment"># txt &#xD30C;&#xC77C;&#xC758; &#xD5E4;&#xB354;(id document label)&#xB294; &#xC81C;&#xC678;&#xD558;&#xAE30;</span>
        data = data[<span class="hljs-number">1</span>:]
    <span class="hljs-keyword">return</span> data

train_data = read_data(<span class="hljs-string">&apos;../ratings_train.txt&apos;</span>)
test_data = read_data(<span class="hljs-string">&apos;../ratings_test.txt&apos;</span>)
</code></pre>
<pre><code class="lang-python">print(len(train_data))
print(len(train_data[<span class="hljs-number">0</span>]))
print(len(test_data))
print(len(test_data[<span class="hljs-number">0</span>]))
</code></pre>
<pre><code>150000
3
50000
3
</code></pre><pre><code class="lang-python"><span class="hljs-keyword">from</span> konlpy.tag <span class="hljs-keyword">import</span> Okt

okt = Okt()
print(okt.pos(<span class="hljs-string">u&apos;&#xC774; &#xBC24; &#xADF8;&#xB0A0;&#xC758; &#xBC18;&#xB527;&#xBD88;&#xC744; &#xB2F9;&#xC2E0;&#xC758; &#xCC3D; &#xAC00;&#xAE4C;&#xC774; &#xBCF4;&#xB0BC;&#xAC8C;&#xC694;&apos;</span>))
</code></pre>
<pre><code>[(&apos;&#xC774;&apos;, &apos;Noun&apos;), (&apos;&#xBC24;&apos;, &apos;Noun&apos;), (&apos;&#xADF8;&#xB0A0;&apos;, &apos;Noun&apos;), (&apos;&#xC758;&apos;, &apos;Josa&apos;), (&apos;&#xBC18;&#xB527;&#xBD88;&apos;, &apos;Noun&apos;), (&apos;&#xC744;&apos;, &apos;Josa&apos;), (&apos;&#xB2F9;&#xC2E0;&apos;, &apos;Noun&apos;), (&apos;&#xC758;&apos;, &apos;Josa&apos;), (&apos;&#xCC3D;&apos;, &apos;Noun&apos;), (&apos;&#xAC00;&#xAE4C;&#xC774;&apos;, &apos;Noun&apos;), (&apos;&#xBCF4;&#xB0BC;&#xAC8C;&#xC694;&apos;, &apos;Verb&apos;)]
</code></pre><pre><code class="lang-python"><span class="hljs-keyword">import</span> json
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tokenize</span><span class="hljs-params">(doc)</span>:</span>
    <span class="hljs-comment"># norm&#xC740; &#xC815;&#xADDC;&#xD654;, stem&#xC740; &#xADFC;&#xC5B4;&#xB85C; &#xD45C;&#xC2DC;&#xD558;&#xAE30;&#xB97C; &#xB098;&#xD0C0;&#xB0C4;</span>
    <span class="hljs-keyword">return</span> [<span class="hljs-string">&apos;/&apos;</span>.join(t) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> okt.pos(doc, norm=<span class="hljs-keyword">True</span>, stem=<span class="hljs-keyword">True</span>)]

<span class="hljs-keyword">if</span> os.path.isfile(<span class="hljs-string">&apos;train_docs.json&apos;</span>):
    <span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;train_docs.json&apos;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
        train_docs = json.load(f)
    <span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;test_docs.json&apos;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
        test_docs = json.load(f)
<span class="hljs-keyword">else</span>:
    train_docs = [(tokenize(row[<span class="hljs-number">1</span>]), row[<span class="hljs-number">2</span>]) <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> train_data]
    test_docs = [(tokenize(row[<span class="hljs-number">1</span>]), row[<span class="hljs-number">2</span>]) <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> test_data]
    <span class="hljs-comment"># JSON &#xD30C;&#xC77C;&#xB85C; &#xC800;&#xC7A5;</span>
    <span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;train_docs.json&apos;</span>, <span class="hljs-string">&apos;w&apos;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> make_file:
        json.dump(train_docs, make_file, ensure_ascii=<span class="hljs-keyword">False</span>, indent=<span class="hljs-string">&quot;\t&quot;</span>)
    <span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;test_docs.json&apos;</span>, <span class="hljs-string">&apos;w&apos;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> make_file:
        json.dump(test_docs, make_file, ensure_ascii=<span class="hljs-keyword">False</span>, indent=<span class="hljs-string">&quot;\t&quot;</span>)

<span class="hljs-comment"># &#xC608;&#xC058;&#xAC8C;(?) &#xCD9C;&#xB825;&#xD558;&#xAE30; &#xC704;&#xD574;&#xC11C; pprint &#xB77C;&#xC774;&#xBE0C;&#xB7EC;&#xB9AC; &#xC0AC;&#xC6A9;</span>
pprint(train_docs[<span class="hljs-number">0</span>])
</code></pre>
<pre><code>[[&apos;&#xC544;/Exclamation&apos;,
  &apos;&#xB354;&#xBE59;/Noun&apos;,
  &apos;../Punctuation&apos;,
  &apos;&#xC9C4;&#xC9DC;/Noun&apos;,
  &apos;&#xC9DC;&#xC99D;&#xB098;&#xB2E4;/Adjective&apos;,
  &apos;&#xBAA9;&#xC18C;&#xB9AC;/Noun&apos;],
 &apos;0&apos;]
</code></pre><pre><code class="lang-python">tokens = [t <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> train_docs <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> d[<span class="hljs-number">0</span>]]
print(len(tokens))
</code></pre>
<pre><code>2159921
</code></pre><pre><code class="lang-python"><span class="hljs-keyword">import</span> nltk
text = nltk.Text(tokens, name=<span class="hljs-string">&apos;NMSC&apos;</span>)

<span class="hljs-comment"># &#xC804;&#xCCB4; &#xD1A0;&#xD070;&#xC758; &#xAC1C;&#xC218;</span>
print(len(text.tokens))

<span class="hljs-comment"># &#xC911;&#xBCF5;&#xC744; &#xC81C;&#xC678;&#xD55C; &#xD1A0;&#xD070;&#xC758; &#xAC1C;&#xC218;</span>
print(len(set(text.tokens)))            

<span class="hljs-comment"># &#xCD9C;&#xD604; &#xBE48;&#xB3C4;&#xAC00; &#xB192;&#xC740; &#xC0C1;&#xC704; &#xD1A0;&#xD070; 10&#xAC1C;</span>
pprint(text.vocab().most_common(<span class="hljs-number">10</span>))
</code></pre>
<pre><code>2159921
49895
[(&apos;./Punctuation&apos;, 67778),
 (&apos;&#xC601;&#xD654;/Noun&apos;, 50818),
 (&apos;&#xD558;&#xB2E4;/Verb&apos;, 41209),
 (&apos;&#xC774;/Josa&apos;, 38540),
 (&apos;&#xBCF4;&#xB2E4;/Verb&apos;, 38538),
 (&apos;&#xC758;/Josa&apos;, 30188),
 (&apos;../Punctuation&apos;, 29055),
 (&apos;&#xAC00;/Josa&apos;, 26627),
 (&apos;&#xC5D0;/Josa&apos;, 26468),
 (&apos;&#xC744;/Josa&apos;, 23118)]
</code></pre><pre><code class="lang-python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> font_manager, rc
%matplotlib inline

font_fname = <span class="hljs-string">&apos;/usr/share/fonts/NanumFont/NanumGothic.ttf&apos;</span>
font_name = font_manager.FontProperties(fname=font_fname).get_name()
rc(<span class="hljs-string">&apos;font&apos;</span>, family=font_name)

plt.figure(figsize=(<span class="hljs-number">20</span>,<span class="hljs-number">10</span>))
text.plot(<span class="hljs-number">50</span>)
</code></pre>
<p><img src="1.1.png" alt="png"></p>
<pre><code class="lang-python"><span class="hljs-comment"># &#xC2DC;&#xAC04;&#xC774; &#xAF64; &#xAC78;&#xB9BD;&#xB2C8;&#xB2E4;! &#xC2DC;&#xAC04;&#xC744; &#xC808;&#xC57D;&#xD558;&#xACE0; &#xC2F6;&#xC73C;&#xBA74; most_common&#xC758; &#xB9E4;&#xAC1C;&#xBCC0;&#xC218;&#xB97C; &#xC904;&#xC5EC;&#xBCF4;&#xC138;&#xC694;.</span>
selected_words = [f[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> text.vocab().most_common(<span class="hljs-number">1000</span>)]

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">term_frequency</span><span class="hljs-params">(doc)</span>:</span>
    <span class="hljs-keyword">return</span> [doc.count(word) <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> selected_words]

train_x = [term_frequency(d) <span class="hljs-keyword">for</span> d, _ <span class="hljs-keyword">in</span> train_docs]
test_x = [term_frequency(d) <span class="hljs-keyword">for</span> d, _ <span class="hljs-keyword">in</span> test_docs]
train_y = [c <span class="hljs-keyword">for</span> _, c <span class="hljs-keyword">in</span> train_docs]
test_y = [c <span class="hljs-keyword">for</span> _, c <span class="hljs-keyword">in</span> test_docs]
</code></pre>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

x_train = np.asarray(train_x).astype(<span class="hljs-string">&apos;float32&apos;</span>)
x_test = np.asarray(test_x).astype(<span class="hljs-string">&apos;float32&apos;</span>)

y_train = np.asarray(train_y).astype(<span class="hljs-string">&apos;float32&apos;</span>)
y_test = np.asarray(test_y).astype(<span class="hljs-string">&apos;float32&apos;</span>)
</code></pre>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> models
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> optimizers
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> losses
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> metrics

model = models.Sequential()
model.add(layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">&apos;relu&apos;</span>, input_shape=(<span class="hljs-number">1000</span>,)))
model.add(layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">&apos;relu&apos;</span>))
model.add(layers.Dense(<span class="hljs-number">1</span>, activation=<span class="hljs-string">&apos;sigmoid&apos;</span>))

model.compile(optimizer=optimizers.RMSprop(lr=<span class="hljs-number">0.001</span>),
             loss=losses.binary_crossentropy,
             metrics=[metrics.binary_accuracy])

model.fit(x_train, y_train, epochs=<span class="hljs-number">10</span>, batch_size=<span class="hljs-number">512</span>)
results = model.evaluate(x_test, y_test)
<span class="hljs-comment"># from keras.models import load_model</span>
<span class="hljs-comment"># model.save(&apos;mnist_mlp_model.h5&apos;)</span>
</code></pre>
<pre><code>Epoch 1/10
150000/150000 [==============================] - 2s 13us/step - loss: 0.4306 - binary_accuracy: 0.8029
Epoch 2/10
150000/150000 [==============================] - 2s 12us/step - loss: 0.3806 - binary_accuracy: 0.8245
Epoch 3/10
150000/150000 [==============================] - 2s 12us/step - loss: 0.3652 - binary_accuracy: 0.8330
Epoch 4/10
150000/150000 [==============================] - 2s 12us/step - loss: 0.3524 - binary_accuracy: 0.8414
Epoch 5/10
150000/150000 [==============================] - 2s 12us/step - loss: 0.3407 - binary_accuracy: 0.8481
Epoch 6/10
150000/150000 [==============================] - 2s 12us/step - loss: 0.3299 - binary_accuracy: 0.8539
Epoch 7/10
150000/150000 [==============================] - 2s 12us/step - loss: 0.3192 - binary_accuracy: 0.8598
Epoch 8/10
150000/150000 [==============================] - 2s 12us/step - loss: 0.3087 - binary_accuracy: 0.8654
Epoch 9/10
150000/150000 [==============================] - 2s 11us/step - loss: 0.2984 - binary_accuracy: 0.8706
Epoch 10/10
150000/150000 [==============================] - 2s 12us/step - loss: 0.2875 - binary_accuracy: 0.8765
50000/50000 [==============================] - 2s 34us/step
</code></pre><pre><code class="lang-python">results
</code></pre>
<pre><code>[0.39590893244743347, 0.82676]
</code></pre><pre><code class="lang-python"><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> load_model
model.save(<span class="hljs-string">&apos;mnist_mlp_model.h5&apos;</span>)
</code></pre>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> models
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> optimizers
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> losses
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> metrics
</code></pre>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> load_model
model = load_model(<span class="hljs-string">&apos;mnist_mlp_model.h5&apos;</span>)
</code></pre>
<pre><code class="lang-python">model
</code></pre>
<pre><code>&lt;tensorflow.python.keras.engine.sequential.Sequential at 0x7f0b80579048&gt;
</code></pre><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_pos_neg</span><span class="hljs-params">(review)</span>:</span>
    token = tokenize(review)
    tf = term_frequency(token)
    data = np.expand_dims(np.asarray(tf).astype(<span class="hljs-string">&apos;float32&apos;</span>), axis=<span class="hljs-number">0</span>)
    score = float(model.predict(data))
    <span class="hljs-keyword">if</span>(score &gt; <span class="hljs-number">0.5</span>):
        print(<span class="hljs-string">&quot;[{}]&#xB294; {:.2f}% &#xD655;&#xB960;&#xB85C; &#xAE0D;&#xC815; &#xB9AC;&#xBDF0;&#xC774;&#xC9C0; &#xC54A;&#xC744;&#xAE4C; &#xCD94;&#xCE21;&#xD574;&#xBD05;&#xB2C8;&#xB2E4;.^^\n&quot;</span>.format(review, score * <span class="hljs-number">100</span>))
    <span class="hljs-keyword">else</span>:
        print(<span class="hljs-string">&quot;[{}]&#xB294; {:.2f}% &#xD655;&#xB960;&#xB85C; &#xBD80;&#xC815; &#xB9AC;&#xBDF0;&#xC774;&#xC9C0; &#xC54A;&#xC744;&#xAE4C; &#xCD94;&#xCE21;&#xD574;&#xBD05;&#xB2C8;&#xB2E4;.^^;\n&quot;</span>.format(review, (<span class="hljs-number">1</span> - score) * <span class="hljs-number">100</span>))
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># from konlpy.tag import Okt</span>
<span class="hljs-comment"># okt = Okt()</span>
<span class="hljs-comment"># def tokenize(doc):</span>
<span class="hljs-comment">#     # norm&#xC740; &#xC815;&#xADDC;&#xD654;, stem&#xC740; &#xADFC;&#xC5B4;&#xB85C; &#xD45C;&#xC2DC;&#xD558;&#xAE30;&#xB97C; &#xB098;&#xD0C0;&#xB0C4;</span>
<span class="hljs-comment">#     return [&apos;/&apos;.join(t) for t in okt.pos(doc, norm=True, stem=True)]</span>
<span class="hljs-comment"># selected_words = [f[0] for f in text.vocab().most_common(1000)]</span>
<span class="hljs-comment"># def term_frequency(doc):</span>
<span class="hljs-comment">#     return [doc.count(word) for word in selected_words]</span>

<span class="hljs-comment"># train_x = model.x_train</span>
<span class="hljs-comment"># test_x = model.x_test</span>
<span class="hljs-comment"># train_y = model.y_train</span>
<span class="hljs-comment"># test_y = model.y_test</span>
predict_pos_neg(<span class="hljs-string">&quot;&#xC62C;&#xD574; &#xCD5C;&#xACE0;&#xC758; &#xC601;&#xD654;! &#xC138; &#xBC88; &#xB118;&#xAC8C; &#xBD10;&#xB3C4; &#xC9C8;&#xB9AC;&#xC9C0;&#xAC00; &#xC54A;&#xB124;&#xC694;.&quot;</span>)
predict_pos_neg(<span class="hljs-string">&quot;&#xBC30;&#xACBD; &#xC74C;&#xC545;&#xC774; &#xC601;&#xD654;&#xC758; &#xBD84;&#xC704;&#xAE30;&#xB791; &#xB108;&#xBB34; &#xC548; &#xB9DE;&#xC558;&#xC2B5;&#xB2C8;&#xB2E4;. &#xBAB0;&#xC785;&#xC5D0; &#xBC29;&#xD574;&#xAC00; &#xB429;&#xB2C8;&#xB2E4;.&quot;</span>)
predict_pos_neg(<span class="hljs-string">&quot;&#xC8FC;&#xC5F0; &#xBC30;&#xC6B0;&#xAC00; &#xC2E0;&#xC778;&#xC778;&#xB370; &#xC5F0;&#xAE30;&#xB97C; &#xC9C4;&#xC9DC; &#xC798; &#xD558;&#xB124;&#xC694;. &#xBAB0;&#xC785;&#xAC10; &#x314E;&#x3137;&#x3137;&quot;</span>)
predict_pos_neg(<span class="hljs-string">&quot;&#xBBFF;&#xACE0; &#xBCF4;&#xB294; &#xAC10;&#xB3C5;&#xC774;&#xC9C0;&#xB9CC; &#xC774;&#xBC88;&#xC5D0;&#xB294; &#xC544;&#xB2C8;&#xB124;&#xC694;&quot;</span>)
predict_pos_neg(<span class="hljs-string">&quot;&#xC8FC;&#xC5F0;&#xBC30;&#xC6B0; &#xB54C;&#xBB38;&#xC5D0; &#xBD24;&#xC5B4;&#xC694;&quot;</span>)
</code></pre>
<pre><code>[&#xC62C;&#xD574; &#xCD5C;&#xACE0;&#xC758; &#xC601;&#xD654;! &#xC138; &#xBC88; &#xB118;&#xAC8C; &#xBD10;&#xB3C4; &#xC9C8;&#xB9AC;&#xC9C0;&#xAC00; &#xC54A;&#xB124;&#xC694;.]&#xB294; 98.79% &#xD655;&#xB960;&#xB85C; &#xAE0D;&#xC815; &#xB9AC;&#xBDF0;&#xC774;&#xC9C0; &#xC54A;&#xC744;&#xAE4C; &#xCD94;&#xCE21;&#xD574;&#xBD05;&#xB2C8;&#xB2E4;.^^

[&#xBC30;&#xACBD; &#xC74C;&#xC545;&#xC774; &#xC601;&#xD654;&#xC758; &#xBD84;&#xC704;&#xAE30;&#xB791; &#xB108;&#xBB34; &#xC548; &#xB9DE;&#xC558;&#xC2B5;&#xB2C8;&#xB2E4;. &#xBAB0;&#xC785;&#xC5D0; &#xBC29;&#xD574;&#xAC00; &#xB429;&#xB2C8;&#xB2E4;.]&#xB294; 60.11% &#xD655;&#xB960;&#xB85C; &#xAE0D;&#xC815; &#xB9AC;&#xBDF0;&#xC774;&#xC9C0; &#xC54A;&#xC744;&#xAE4C; &#xCD94;&#xCE21;&#xD574;&#xBD05;&#xB2C8;&#xB2E4;.^^

[&#xC8FC;&#xC5F0; &#xBC30;&#xC6B0;&#xAC00; &#xC2E0;&#xC778;&#xC778;&#xB370; &#xC5F0;&#xAE30;&#xB97C; &#xC9C4;&#xC9DC; &#xC798; &#xD558;&#xB124;&#xC694;. &#xBAB0;&#xC785;&#xAC10; &#x314E;&#x3137;&#x3137;]&#xB294; 93.62% &#xD655;&#xB960;&#xB85C; &#xAE0D;&#xC815; &#xB9AC;&#xBDF0;&#xC774;&#xC9C0; &#xC54A;&#xC744;&#xAE4C; &#xCD94;&#xCE21;&#xD574;&#xBD05;&#xB2C8;&#xB2E4;.^^

[&#xBBFF;&#xACE0; &#xBCF4;&#xB294; &#xAC10;&#xB3C5;&#xC774;&#xC9C0;&#xB9CC; &#xC774;&#xBC88;&#xC5D0;&#xB294; &#xC544;&#xB2C8;&#xB124;&#xC694;]&#xB294; 71.52% &#xD655;&#xB960;&#xB85C; &#xBD80;&#xC815; &#xB9AC;&#xBDF0;&#xC774;&#xC9C0; &#xC54A;&#xC744;&#xAE4C; &#xCD94;&#xCE21;&#xD574;&#xBD05;&#xB2C8;&#xB2E4;.^^;

[&#xC8FC;&#xC5F0;&#xBC30;&#xC6B0; &#xB54C;&#xBB38;&#xC5D0; &#xBD24;&#xC5B4;&#xC694;]&#xB294; 78.34% &#xD655;&#xB960;&#xB85C; &#xBD80;&#xC815; &#xB9AC;&#xBDF0;&#xC774;&#xC9C0; &#xC54A;&#xC744;&#xAE4C; &#xCD94;&#xCE21;&#xD574;&#xBD05;&#xB2C8;&#xB2E4;.^^;
</code></pre><pre><code class="lang-python">predict_pos_neg(<span class="hljs-string">&quot;&#xC6EC;&#xB9CC;&#xD558;&#xBA74; &#xD3C9;&#xC810; &#xC88B;&#xAC8C; &#xB0A8;&#xAE30;&#xB294;&#xD3B8;&#xC778;&#xB370; &#xC774;&#xAC74;&#xC544;&#xB2CC;&#xB4EF; &#xCE74;&#xBA54;&#xB77C;&#xB9C8; &#xD63C;&#xB780;&#xC2A4;&#xB7FD;&#xAC8C; &#xCC0D;&#xACE0; &#xC561;&#xC158;&#xC601;&#xD654; &#xBCF4;&#xBA74;&#xC11C; &#xC911;&#xAC04;&#xC5D0; &#xC878;&#xC74C; &#xC3DF;&#xC544;&#xC9C0;&#xB294;&#xC804;&#xAC1C;&#xB294; &#xCC98;&#xC74C; &#xC561;&#xC158;&#xB3C4; &#xC2E0;&#xC120;&#xD55C;&#xAC70; &#xC5C6;&#xC74C;... &#xD3C9;&#xB860;&#xAC00;&#xB4E4; &#xC774;&#xAC8C; &#xC544;&#xCFE0;&#xC544;&#xB9E8;&#xC774;&#xB791; &#xB3D9;&#xAE09;&#xC778; 6.8&#xC810;&#xC774;&#xB77C;&#xACE0;? &#x314B;&#x314B; &#xC9C4;&#xC9DC; &#xBD81;&#xD55C;&#xC774;&#xBBF8;&#xC9C0; &#xC88B;&#xAC8C; &#xB098;&#xC624;&#xACE0; &#xBC18;&#xBBF8;&#xC598;&#xAE30;&#xB098;&#xC624;&#xBA74; &#xD3C9;&#xC810; &#xB192;&#xC74C;&quot;</span>)
</code></pre>
<pre><code>[&#xC6EC;&#xB9CC;&#xD558;&#xBA74; &#xD3C9;&#xC810; &#xC88B;&#xAC8C; &#xB0A8;&#xAE30;&#xB294;&#xD3B8;&#xC778;&#xB370; &#xC774;&#xAC74;&#xC544;&#xB2CC;&#xB4EF; &#xCE74;&#xBA54;&#xB77C;&#xB9C8; &#xD63C;&#xB780;&#xC2A4;&#xB7FD;&#xAC8C; &#xCC0D;&#xACE0; &#xC561;&#xC158;&#xC601;&#xD654; &#xBCF4;&#xBA74;&#xC11C; &#xC911;&#xAC04;&#xC5D0; &#xC878;&#xC74C; &#xC3DF;&#xC544;&#xC9C0;&#xB294;&#xC804;&#xAC1C;&#xB294; &#xCC98;&#xC74C; &#xC561;&#xC158;&#xB3C4; &#xC2E0;&#xC120;&#xD55C;&#xAC70; &#xC5C6;&#xC74C;... &#xD3C9;&#xB860;&#xAC00;&#xB4E4; &#xC774;&#xAC8C; &#xC544;&#xCFE0;&#xC544;&#xB9E8;&#xC774;&#xB791; &#xB3D9;&#xAE09;&#xC778; 6.8&#xC810;&#xC774;&#xB77C;&#xACE0;? &#x314B;&#x314B; &#xC9C4;&#xC9DC; &#xBD81;&#xD55C;&#xC774;&#xBBF8;&#xC9C0; &#xC88B;&#xAC8C; &#xB098;&#xC624;&#xACE0; &#xBC18;&#xBBF8;&#xC598;&#xAE30;&#xB098;&#xC624;&#xBA74; &#xD3C9;&#xC810; &#xB192;&#xC74C;]&#xB294; 99.24% &#xD655;&#xB960;&#xB85C; &#xBD80;&#xC815; &#xB9AC;&#xBDF0;&#xC774;&#xC9C0; &#xC54A;&#xC744;&#xAE4C; &#xCD94;&#xCE21;&#xD574;&#xBD05;&#xB2C8;&#xB2E4;.^^;
</code></pre><pre><code class="lang-python">

</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="7.html" class="navigation navigation-prev " aria-label="Previous page: 링크">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="9.md" class="navigation navigation-next " aria-label="Next page: 시각화 예제 1">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"네이버 영화 리뷰 분석 - 테스트","level":"1.3","depth":1,"next":{"title":"시각화 예제 1","level":"1.4","depth":1,"path":"9.md","ref":"9.md","articles":[]},"previous":{"title":"링크","level":"1.2","depth":1,"path":"7.md","ref":"7.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"8.md","mtime":"2019-01-03T02:39:16.265Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-01-15T23:41:20.868Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

